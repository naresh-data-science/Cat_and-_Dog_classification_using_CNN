{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2fa0c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5edd692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten ,Conv2D, MaxPool2D, Dropout, Activation, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, Adamax, Adagrad\n",
    "from tensorflow.keras.activations import sigmoid, relu, softmax\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d976416",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/Neural Network/CNN/cat and dog/archive (3)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d034b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"D:/Neural Network/CNN/cat and dog/archive (3)/training_set/training_set\"\n",
    "test_path = \"D:/Neural Network/CNN/cat and dog/archive (3)/test_set/test_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f62f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width , img_height = 150,150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b17970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Neural Network/CNN/cat and dog/archive (3)/training_set/training_set\\\\cats',\n",
       " 'D:/Neural Network/CNN/cat and dog/archive (3)/training_set/training_set\\\\dogs']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "glob(\"D:/Neural Network/CNN/cat and dog/archive (3)/training_set/training_set/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f0fd2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Neural Network/CNN/cat and dog/archive (3)/test_set/test_set\\\\cats',\n",
       " 'D:/Neural Network/CNN/cat and dog/archive (3)/test_set/test_set\\\\dogs']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(\"D:/Neural Network/CNN/cat and dog/archive (3)/test_set/test_set/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "492164f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=1/255,\n",
    ")\n",
    "test_gen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e28d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['cats','dogs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56e40ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n",
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_gen.flow_from_directory(train_path,target_size=(img_width,img_height),classes=labels,class_mode=\"categorical\",batch_size=256)\n",
    "test = test_gen.flow_from_directory(test_path,target_size=(img_width,img_height),classes=labels,class_mode=\"categorical\",batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d93fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128,kernel_size = (3,3), input_shape =(img_height,img_width,3),padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,kernel_size= (3,3),padding= 'same',activation= 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32,activation=('relu')))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3054bbbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 150, 150, 128)     3584      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 75, 75, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 75, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 37, 37, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 37, 37, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 37, 37, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 18, 18, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 18, 18, 32)        0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18, 18, 32)        1056      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10368)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                331808    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 428,737\n",
      "Trainable params: 428,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0c551eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer='adam',loss= \"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb6ba00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(train,epochs\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(train,epochs= 10, validation_data=(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ccd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = model.history.history['loss']\n",
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = model.history.history['accuracy']\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0678b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.history.history['val_loss']\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = model.history.history['val_accuracy']\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(np.arange(epochs),train_loss,color='red', label='train_loss')\n",
    "plt.plot(np.arange(epochs),train_acc,color='blue',label='train_acc')\n",
    "plt.plot(np.arange(epochs),test_loss,color='green',label='test_loss')\n",
    "plt.plot(np.arange(epochs),test_acc,color='yellow',label='test_acc')\n",
    "plt.legend()\n",
    "plt.xlabel(epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd432af",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d211d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1979ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(path):\n",
    "    img = cv2.imread(path)\n",
    "    im_resize = cv2.resize(img,(img_height,img_width),interpolation = cv2.INTER_LINEAR)\n",
    "    plt.imshow(cv2.cvtColor(im_resize,cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    \n",
    "    image_pred = image.load_img(path, target_size=(img_height,img_width))\n",
    "    image_pred = image.img_to_array(image_pred)\n",
    "    a = np.expand_dims(image_pred,axis = 0)\n",
    "    #print(a)\n",
    "    result = model.predict(a)\n",
    "    print('predicted_image =',result)\n",
    "    if result > .05:\n",
    "        print(\"cat\")\n",
    "    else:\n",
    "        print(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d43824",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun(\"D:/Neural Network/CNN/kamal/GettyImages-988013222-scaled-e1618857975729.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e362639",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun(\"D:/Neural Network/CNN/kamal/download.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun(\"D:/Neural Network/CNN/kamal/1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75327390",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fun(\"D:/Neural Network/CNN/kamal/00d1cb2ec8b263ae076ff95cae513a88.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f33170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bffce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36e7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f471abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
